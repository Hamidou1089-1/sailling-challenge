# Configuration optimisée pour DQN avec NoisyNet + PER
# 12000 épisodes avec curriculum learning

agent:
  # Learning
  learning_rate: 0.007
  lr_decay: 0.99995  # Decay lent pour 12k épisodes (exp(-0.00005) par step)
  gamma: 0.99
  
  # Buffer
  buffer_capacity: 200000
  batch_size: 128
  
  # Target network
  target_update_freq: 1000  # Plus fréquent avec PER (toutes les 500 steps)
  
  # Algorithme
  use_double_dqn: true
  use_noisy_net: true  # Remplace epsilon-greedy
  use_per: true        # Prioritized Experience Replay
  
  # PER parameters
  per_alpha: 0.6           # Niveau de priorisation (0=uniforme, 1=full priorité)
  per_beta_start: 0.4      # Correction initiale du biais
  per_beta_frames: 120000  # ~12k episodes * 10 steps/episode moyenne

training:
  num_episodes: 12000
  eval_freq: 100    # Évalue tous les 100 épisodes
  save_freq: 2000   # Sauvegarde tous les 1000 épisodes
  
  # Scenarios d'entraînement (curriculum learning activé automatiquement)
  train_scenarios:
    - training_1

checkpoint:
  save_dir: checkpoints/dqn

logging:
  experiment_name: noisynet_per_12k
  tensorboard: true